diff --git a/drivers/net/ethernet/mediatek/gsw_mt7621.c b/drivers/net/ethernet/mediatek/gsw_mt7621.c
index a903ccbe..4ea8e0ef 100644
--- a/drivers/net/ethernet/mediatek/gsw_mt7621.c
+++ b/drivers/net/ethernet/mediatek/gsw_mt7621.c
@@ -99,11 +99,11 @@ static void mt7621_hw_init(struct mt7620_gsw *gsw, struct device_node *np)
 	usleep_range(10, 20);
 
 	if ((rt_sysc_r32(SYSC_REG_CHIP_REV_ID) & 0xFFFF) == 0x0101) {
-		/* (GE1, Force 1000M/FD, FC ON, MAX_RX_LENGTH 2k) */
+		/* (GE1, Force 1000M/FD, FC ON, MAX_RX_LENGTH 1536) */
 		mtk_switch_w32(gsw, 0x2305e30b, GSW_REG_MAC_P0_MCR);
 		mt7530_mdio_w32(gsw, 0x3600, 0x5e30b);
 	} else {
-		/* (GE1, Force 1000M/FD, FC ON, MAX_RX_LENGTH 2k) */
+		/* (GE1, Force 1000M/FD, FC ON, MAX_RX_LENGTH 1536) */
 		mtk_switch_w32(gsw, 0x2305e33b, GSW_REG_MAC_P0_MCR);
 		mt7530_mdio_w32(gsw, 0x3600, 0x5e33b);
 	}
@@ -186,6 +186,22 @@ static void mt7621_hw_init(struct mt7620_gsw *gsw, struct device_node *np)
 	mt7530_mdio_w32(gsw, 0x7a74, 0x44);
 	mt7530_mdio_w32(gsw, 0x7a7c, 0x44);
 
+	/* Disable EEE */
+	for (i = 0; i <= 4; i++) {
+		_mt7620_mii_write(gsw, i, 13, 0x7);
+		_mt7620_mii_write(gsw, i, 14, 0x3C);
+		_mt7620_mii_write(gsw, i, 13, 0x4007);
+		_mt7620_mii_write(gsw, i, 14, 0x0);
+	}
+
+	/* Disable EEE 10Base-Te */
+	for (i = 0; i <= 4; i++) {
+		_mt7620_mii_write(gsw, i, 13, 0x1f);
+		_mt7620_mii_write(gsw, i, 14, 0x027b);
+		_mt7620_mii_write(gsw, i, 13, 0x401f);
+		_mt7620_mii_write(gsw, i, 14, 0x1177);
+	}
+
 	/* turn on all PHYs */
 	for (i = 0; i <= 4; i++) {
 		val = _mt7620_mii_read(gsw, i, 0);
diff --git a/drivers/net/ethernet/mediatek/mtk_eth_soc.c b/drivers/net/ethernet/mediatek/mtk_eth_soc.c
index 8c71a92f..6ab48882 100644
--- a/drivers/net/ethernet/mediatek/mtk_eth_soc.c
+++ b/drivers/net/ethernet/mediatek/mtk_eth_soc.c
@@ -544,7 +544,7 @@ static inline u32 fe_empty_txd(struct fe_tx_ring *ring)
 	barrier();
 	return (u32)(ring->tx_ring_size -
 			((ring->tx_next_idx - ring->tx_free_idx) &
-			 (ring->tx_ring_size - 1)));
+			 (ring->tx_ring_size - 1)) - 1);
 }
 
 static int fe_tx_map_dma(struct sk_buff *skb, struct net_device *dev,
@@ -774,6 +774,11 @@ static int fe_start_xmit(struct sk_buff *skb, struct net_device *dev)
 	int tx_num;
 	int len = skb->len;
 
+	if (unlikely(test_bit(__FE_DOWN, &priv->state))) {
+		dev_kfree_skb_any(skb);
+		return NETDEV_TX_OK;
+	}
+
 	if (fe_skb_padto(skb, priv)) {
 		netif_warn(priv, tx_err, dev, "tx padding failed!\n");
 		return NETDEV_TX_OK;
@@ -882,17 +887,17 @@ release_desc:
 			rxd->rxd2 = RX_DMA_LSO;
 
 		ring->rx_calc_idx = idx;
+		done++;
+	}
+
+	if (done) {
 		/* make sure that all changes to the dma ring are flushed before
 		 * we continue
 		 */
 		wmb();
 		fe_reg_w32(ring->rx_calc_idx, FE_REG_RX_CALC_IDX0);
-		done++;
 	}
 
-	if (done < budget)
-		fe_reg_w32(rx_intr, FE_REG_FE_INT_STATUS);
-
 	return done;
 }
 
@@ -928,14 +933,7 @@ static int fe_poll_tx(struct fe_priv *priv, int budget, u32 tx_intr,
 	}
 	ring->tx_free_idx = idx;
 
-	if (idx == hwidx) {
-		/* read hw index again make sure no new tx packet */
-		hwidx = fe_reg_r32(FE_REG_TX_DTX_IDX0);
-		if (idx == hwidx)
-			fe_reg_w32(tx_intr, FE_REG_FE_INT_STATUS);
-		else
-			*tx_again = 1;
-	} else {
+	if (idx != hwidx && done) {
 		*tx_again = 1;
 	}
 
@@ -958,6 +956,11 @@ static int fe_poll(struct napi_struct *napi, int budget)
 	u32 status, fe_status, status_reg, mask;
 	u32 tx_intr, rx_intr, status_intr;
 
+	if (unlikely(test_bit(__FE_DOWN, &priv->state))) {
+		napi_complete(napi);
+		return 0;
+	}
+
 	status = fe_reg_r32(FE_REG_FE_INT_STATUS);
 	fe_status = status;
 	tx_intr = priv->soc->tx_int;
@@ -967,6 +970,10 @@ static int fe_poll(struct napi_struct *napi, int budget)
 	rx_done = 0;
 	tx_again = 0;
 
+	if ((status & (tx_intr | rx_intr))) {
+		fe_reg_w32((status & (tx_intr | rx_intr)), FE_REG_FE_INT_STATUS);
+	}
+
 	if (fe_reg_table[FE_REG_FE_INT_STATUS2]) {
 		fe_status = fe_reg_r32(FE_REG_FE_INT_STATUS2);
 		status_reg = FE_REG_FE_INT_STATUS2;
@@ -974,11 +981,15 @@ static int fe_poll(struct napi_struct *napi, int budget)
 		status_reg = FE_REG_FE_INT_STATUS;
 	}
 
-	if (status & tx_intr)
-		tx_done = fe_poll_tx(priv, budget, tx_intr, &tx_again);
+	tx_done = fe_poll_tx(priv, budget, tx_intr, &tx_again);
+	if (tx_done && !tx_again && !(status & tx_intr)) {
+		fe_reg_w32(tx_intr, FE_REG_FE_INT_STATUS);
+	}
 
-	if (status & rx_intr)
-		rx_done = fe_poll_rx(napi, budget, priv, rx_intr);
+	rx_done = fe_poll_rx(napi, budget, priv, rx_intr);
+	if (rx_done && rx_done < budget && !(status & rx_intr)) {
+		fe_reg_w32(rx_intr, FE_REG_FE_INT_STATUS);
+	}
 
 	if (unlikely(fe_status & status_intr)) {
 		if (hwstat && spin_trylock(&hwstat->stats_lock)) {
@@ -996,20 +1007,22 @@ static int fe_poll(struct napi_struct *napi, int budget)
 	}
 
 	if (!tx_again && (rx_done < budget)) {
-		status = fe_reg_r32(FE_REG_FE_INT_STATUS);
-		if (status & (tx_intr | rx_intr)) {
-			/* let napi poll again */
-			rx_done = budget;
-			goto poll_again;
-		}
+		bool napi_complete_done_status;
 
-		napi_complete(napi);
-		fe_int_enable(tx_intr | rx_intr);
+		napi_complete_done_status=!unlikely(test_bit(NAPI_STATE_NPSVC, &napi->state));
+
+		if (napi_complete_done_status)
+		{
+			napi_complete_done(napi, rx_done);
+		}
+		
+		if (likely(napi_complete_done_status && !test_bit(__FE_DOWN, &priv->state))) {
+			fe_int_enable(tx_intr | rx_intr);
+		}
 	} else {
 		rx_done = budget;
 	}
 
-poll_again:
 	return rx_done;
 }
 
@@ -1157,7 +1170,8 @@ static int fe_hw_init(struct net_device *dev)
 	/* disable delay interrupt */
 	fe_reg_w32(0, FE_REG_DLY_INT_CFG);
 
-	fe_int_disable(priv->soc->tx_int | priv->soc->rx_int);
+	/* disable all interrupts during hw init */
+	fe_int_disable(~0);
 
 	/* frame engine will push VLAN tag regarding to VIDX feild in Tx desc */
 	if (fe_reg_table[FE_REG_FE_DMA_VID_BASE])
@@ -1180,25 +1194,6 @@ static int fe_hw_init(struct net_device *dev)
 static int fe_open(struct net_device *dev)
 {
 	struct fe_priv *priv = netdev_priv(dev);
-	unsigned long flags;
-	u32 val;
-	int err;
-
-	err = fe_init_dma(priv);
-	if (err) {
-		fe_free_dma(priv);
-		return err;
-	}
-
-	spin_lock_irqsave(&priv->page_lock, flags);
-
-	val = FE_TX_WB_DDONE | FE_RX_DMA_EN | FE_TX_DMA_EN;
-	if (priv->flags & FE_FLAG_RX_2B_OFFSET)
-		val |= FE_RX_2B_OFFSET;
-	val |= priv->soc->pdma_glo_cfg;
-	fe_reg_w32(val, FE_REG_PDMA_GLO_CFG);
-
-	spin_unlock_irqrestore(&priv->page_lock, flags);
 
 	if (priv->phy)
 		priv->phy->start(priv);
@@ -1206,6 +1201,8 @@ static int fe_open(struct net_device *dev)
 	if (priv->soc->has_carrier && priv->soc->has_carrier(priv))
 		netif_carrier_on(dev);
 
+	clear_bit(__FE_DOWN, &priv->state);
+
 	napi_enable(&priv->rx_napi);
 	fe_int_enable(priv->soc->tx_int | priv->soc->rx_int);
 	netif_start_queue(dev);
@@ -1216,9 +1213,10 @@ static int fe_open(struct net_device *dev)
 static int fe_stop(struct net_device *dev)
 {
 	struct fe_priv *priv = netdev_priv(dev);
-	unsigned long flags;
 	int i;
 
+	set_bit(__FE_DOWN, &priv->state);
+
 	netif_tx_disable(dev);
 	fe_int_disable(priv->soc->tx_int | priv->soc->rx_int);
 	napi_disable(&priv->rx_napi);
@@ -1226,13 +1224,6 @@ static int fe_stop(struct net_device *dev)
 	if (priv->phy)
 		priv->phy->stop(priv);
 
-	spin_lock_irqsave(&priv->page_lock, flags);
-
-	fe_reg_w32(fe_reg_r32(FE_REG_PDMA_GLO_CFG) &
-		     ~(FE_TX_WB_DDONE | FE_RX_DMA_EN | FE_TX_DMA_EN),
-		     FE_REG_PDMA_GLO_CFG);
-	spin_unlock_irqrestore(&priv->page_lock, flags);
-
 	/* wait dma stop */
 	for (i = 0; i < 10; i++) {
 		if (fe_reg_r32(FE_REG_PDMA_GLO_CFG) &
@@ -1243,8 +1234,6 @@ static int fe_stop(struct net_device *dev)
 		break;
 	}
 
-	fe_free_dma(priv);
-
 	return 0;
 }
 
@@ -1253,6 +1242,8 @@ static int __init fe_init(struct net_device *dev)
 	struct fe_priv *priv = netdev_priv(dev);
 	struct device_node *port;
 	const char *mac_addr;
+	unsigned long flags;
+	u32 val;
 	int err;
 
 	priv->soc->reset_fe();
@@ -1297,6 +1288,21 @@ static int __init fe_init(struct net_device *dev)
 	if ((priv->flags & FE_FLAG_HAS_SWITCH) && priv->soc->switch_config)
 		priv->soc->switch_config(priv);
 
+	set_bit(__FE_DOWN, &priv->state);
+	err = fe_init_dma(priv);
+	if (err) {
+		fe_free_dma(priv);
+		goto err_phy_disconnect;
+	}
+
+	spin_lock_irqsave(&priv->page_lock, flags);
+	val = FE_TX_WB_DDONE | FE_RX_DMA_EN | FE_TX_DMA_EN;
+	if (priv->flags & FE_FLAG_RX_2B_OFFSET)
+		val |= FE_RX_2B_OFFSET;
+	val |= priv->soc->pdma_glo_cfg;
+	fe_reg_w32(val, FE_REG_PDMA_GLO_CFG);
+	spin_unlock_irqrestore(&priv->page_lock, flags);
+
 	return 0;
 
 err_phy_disconnect:
@@ -1309,8 +1315,16 @@ err_phy_disconnect:
 
 static void fe_uninit(struct net_device *dev)
 {
+	unsigned long flags;
 	struct fe_priv *priv = netdev_priv(dev);
 
+	spin_lock_irqsave(&priv->page_lock, flags);
+	fe_reg_w32(fe_reg_r32(FE_REG_PDMA_GLO_CFG) &
+		     ~(FE_TX_WB_DDONE | FE_RX_DMA_EN | FE_TX_DMA_EN),
+		     FE_REG_PDMA_GLO_CFG);
+	spin_unlock_irqrestore(&priv->page_lock, flags);
+	fe_free_dma(priv);
+
 	if (priv->phy)
 		priv->phy->disconnect(priv);
 	fe_mdio_cleanup(priv);
diff --git a/drivers/net/ethernet/mediatek/mtk_eth_soc.h b/drivers/net/ethernet/mediatek/mtk_eth_soc.h
index 05f550fa..2f31d7ae 100644
--- a/drivers/net/ethernet/mediatek/mtk_eth_soc.h
+++ b/drivers/net/ethernet/mediatek/mtk_eth_soc.h
@@ -470,10 +470,16 @@ struct fe_rx_ring {
 	u16 rx_calc_idx;
 };
 
+enum fe_state_t {
+	__FE_DOWN,
+};
+
 struct fe_priv {
 	/* make sure that register operations are atomic */
 	spinlock_t			page_lock;
 
+	unsigned long state;
+
 	struct fe_soc_data		*soc;
 	struct net_device		*netdev;
 	struct device_node		*switch_np;
